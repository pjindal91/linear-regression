{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the notebook we will use the diabetes dataset to understand the maths behind Linear Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "X = pd.DataFrame(diabetes_X)\n",
    "X.columns = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "\n",
    "y = pd.DataFrame(diabetes_y)\n",
    "y.columns = ['disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Regression Equation and Residual Sum of Squares(RSS) is given by:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1x + \\epsilon \\\\\n",
    "\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x \\\\\n",
    "RSS = (y_1 - \\hat{\\beta_0} - \\hat{\\beta_1}x_1)^2+(y_2 - \\hat{\\beta_0} - \\hat{\\beta_1}x_2)^2 + ... + (y_n - \\hat{\\beta_0} - \\hat{\\beta_1}x_n)^2 \\\\\n",
    "RSS = \\sum_{i=0}^n(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_i)^2 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$\n",
    "\n",
    "To solve for $\\beta_0$ and $\\beta_1$, the normal Equations for the above are given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta{RSS}}{\\delta{\\hat{\\beta_0}}} = -2\\sum (y_i - \\hat{\\beta_0}+\\hat{\\beta_1}x_i) = 0 \\\\\n",
    "\\frac{\\delta{RSS}}{\\delta{\\hat{\\beta_1}}} = -2x_i\\sum (y_i - \\hat{\\beta_0}+\\hat{\\beta_1}x_i) = 0 \\\\\n",
    "$$\n",
    "\n",
    "Solving the first normal equation for $\\beta_0$:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta{RSS}}{\\delta{\\hat{\\beta_0}}} = -2\\sum (y_i - \\hat{\\beta_0}+\\hat{\\beta_1}x_i) = 0 \\\\\n",
    "\\sum{y_i} - n\\hat{\\beta_0}-\\hat{\\beta_1}\\sum{x_i} = 0 \\\\\n",
    "\\underline{\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}} \\;\\;\\;\\;\\;\n",
    "where \\;\n",
    "\\bar{x} = \\frac{\\sum{x_i}}{n} \\;\\;\\;\n",
    "\\bar{y} = \\frac{\\sum{y_i}}{n}\n",
    "$$\n",
    "\n",
    "Solving the second normal equation for $\\beta_1$:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta{RSS}}{\\delta{\\hat{\\beta_1}}} = \\sum{x_i}(y_i - \\hat{\\beta_0}+\\hat{\\beta_1}x_i) = 0 \\\\\n",
    "\\sum{x_i}(y_i - \\bar{y} + \\hat{\\beta_1}\\bar{x} - \\hat{\\beta_1}x_i) = 0 \\;\\;\\;\\;\n",
    "using \\; \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x} \\\\\n",
    "\\sum{x_i}(y_i-\\bar{y}) = \\hat{\\beta_1}\\sum{(x_i-\\bar{x})x_i} \\\\\n",
    "\\hat{\\beta_1} = \\frac{\\sum{(y_i-\\bar{y})x_i}}{\\sum{(x_i-\\bar{x})x_i}} \\\\\n",
    "\\underline{\\hat{\\beta_1}= \\frac{\\sum{(y_i-\\bar{y})(x_i-\\bar{x}})}{\\sum{(x_i-\\bar{x})^2}}} \\;\\;\\;\\;\\;\n",
    "where \\;\n",
    "\\sum{(y_i-\\bar{y})}\\bar{x} = 0 \\;\\;\n",
    "\\sum{(x_i-\\bar{x})}\\bar{x} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                disease   R-squared:                       0.035\n",
      "Model:                            OLS   Adj. R-squared:                  0.033\n",
      "Method:                 Least Squares   F-statistic:                     16.10\n",
      "Date:                Fri, 03 Jul 2020   Prob (F-statistic):           7.06e-05\n",
      "Time:                        21:04:51   Log-Likelihood:                -2539.2\n",
      "No. Observations:                 442   AIC:                             5082.\n",
      "Df Residuals:                     440   BIC:                             5091.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age          304.1831     75.806      4.013      0.000     155.196     453.170\n",
      "const        152.1335      3.606     42.192      0.000     145.047     159.220\n",
      "==============================================================================\n",
      "Omnibus:                       52.996   Durbin-Watson:                   1.921\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.909\n",
      "Skew:                           0.438   Prob(JB):                     1.43e-06\n",
      "Kurtosis:                       2.167   Cond. No.                         21.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# For this example we will chose the Age feature solely \n",
    "\n",
    "X_age = X.age\n",
    "\n",
    "X_age = sm.add_constant(X_age, prepend=False)\n",
    "model = sm.OLS(y, X_age)\n",
    "results = model.fit()\n",
    "rss = results.ssr\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated coeff is 304.1830745282948\n",
      "Calculated intercept is 152.13348416289594\n",
      "\n",
      "It can be seen that the values calculated using the formulas are same as the values calculated by the statsmodel.         Our maths holds up!\n"
     ]
    }
   ],
   "source": [
    "# Lets verify if based on our formulas of coeff and intercept we reach the same values\n",
    "\n",
    "y_mean = [np.mean(y.disease)] * 442\n",
    "\n",
    "y_diff = y.disease - y_mean\n",
    "x_mean = 0 # Data is 0 mean\n",
    "coeff = np.sum((y.disease - y_mean) * (X_age.age - x_mean)) / np.sum(X_age.age**2)\n",
    "print(f\"Calculated coeff is {coeff}\")\n",
    "\n",
    "intercept = y_mean[0] - coeff * x_mean\n",
    "print(f\"Calculated intercept is {intercept}\")\n",
    "\n",
    "print()\n",
    "print(\"It can be seen that the values calculated using the formulas are same as the values calculated by the statsmodel. \\\n",
    "        Our maths holds up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error of Coefficients\n",
    "\n",
    "Since we don't have the true mean of the $y$ but only sample mean based on $n$ observations, we don't know the true $\\beta_0$ and $\\beta_1$, we only have $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$. Let's see how far are we from true $\\beta_0$ and $\\beta_1$ by using standard error, which is given by:\n",
    "$$\n",
    "SE(\\hat{\\beta_0})^2 = \\sigma^2[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}] \\\\\n",
    "SE(\\hat{\\beta_1})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2} \\;\\;\\;\n",
    "$$\n",
    "where $\\sigma^2$ is variance of $\\epsilon$ which is the uncontrolled error in $y = \\beta_0 + \\beta_1x + \\epsilon$, which again is something we don't know.\n",
    "\n",
    "The approximation of $\\sigma$ derived from maximum likelihood for a uncorrelated, zero mean, normally distributed $\\epsilon$, is given by Residual Standard Error\n",
    "$$\n",
    "\\sigma = RSE = \\sqrt{\\frac{RSS}{(n-p-1)}} = \\sqrt{\\frac{RSS}{(n-2)}} \\;\\;\\;\\; p = Number \\; of \\; features\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error for coeff is 75.8059991270286\n",
      "Standard error for intercept is 3.605723675064678\n",
      "Computed standard error for coeff is 75.80599912702861\n",
      "Computed standard error for intercept is 3.6057236750646777\n",
      "\n",
      "HOORAY! Values are same.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard error for coeff is {results.bse[0]}\")\n",
    "print(f\"Standard error for intercept is {results.bse[1]}\")\n",
    "\n",
    "# Lets try to verify this as well based on the above formula\n",
    "\n",
    "sigma = np.sqrt(rss/(442-2))\n",
    "\n",
    "se_coeff = np.sqrt((sigma**2)/np.sum((X_age.age - x_mean)**2))\n",
    "print(f\"Computed standard error for coeff is {se_coeff}\")\n",
    "\n",
    "se_intercept = np.sqrt(sigma**2*(1/442)) # The second term with x_mean can be avoided since x_mean is zero\n",
    "print(f\"Computed standard error for intercept is {se_intercept}\")\n",
    "\n",
    "print()\n",
    "print(\"HOORAY! Values are same.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Coefficients\n",
    "In order to know whether a particular feature is important or not, we use the null hypothesis and see if it can be discarded. \n",
    "\n",
    "The null hypothesis $H_0$ says that there is no relationship between a feature $X$ and output $Y$, hence $\\beta = 0$\n",
    "If there is relationship between the feature and ouput, then $\\beta$ would be sufficiently far from 0. This means that the value of $\\beta$ would be atleast some number of standard deviations away from zero which is given by $t-statistic$, resulting in $p-value$ being < 0.05\n",
    "\n",
    "Based on the above, $t-statistic$ is given by:\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta_1} - 0}{SE({\\hat{\\beta_1}})}\n",
    "$$\n",
    "\n",
    "Using this and the degrees of freedom given by (n-p), we can compute the $p-value$ to check if the value of the coefficient is small enough to indicate that there is relationship between feature and output is not due to chance, and null hypothesis can be discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "We know that y is drawn from the Normal Distribution given by:\n",
    "$$\n",
    "y \\sim N(\\beta_0 + \\beta_1x, \\sigma^2)\n",
    "$$\n",
    "\n",
    "As a result $\\hat{\\beta_0}$ is also normally distributed:\n",
    "$$\n",
    "\\hat{\\beta_0} \\sim N(\\beta_0, \\sigma^2[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}]) \\\\\n",
    "\\hat{\\beta_0} \\sim N(\\beta_0, SE(\\hat{\\beta_0})^2)\n",
    "$$\n",
    "\n",
    "And $\\hat{\\beta_1}$ is also normally distributed:\n",
    "$$\n",
    "\\hat{\\beta_1} \\sim N(\\beta_1, \\frac{\\sigma^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}) \\\\\n",
    "\\hat{\\beta_1} \\sim N(\\beta_1, SE(\\hat{\\beta_1})^2)\n",
    "$$\n",
    "\n",
    "Using the above, the confidence interval for 95% is given by:\n",
    "$$\n",
    "\\hat{\\beta_0} - t_{0.025, n-2}SE(\\hat{\\beta_0}) \\; \\leq \\beta_0 \\leq \\; \\hat{\\beta_0} + t_{0.025, n-2}SE(\\hat{\\beta_0}) \\\\\n",
    "\\hat{\\beta_1} - t_{0.025, n-2}SE(\\hat{\\beta_1}) \\; \\leq \\beta_1 \\leq \\; \\hat{\\beta_1} + t_{0.025, n-2}SE(\\hat{\\beta_1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025 confidence level for coeff is 155.193981254\n",
      "0.975 confidence level for coeff is 453.17216674599996\n",
      "0.025 confidence level for intercept is 145.046801912\n",
      "0.975 confidence level for intercept is 159.220166088\n"
     ]
    }
   ],
   "source": [
    "# Lets also verify the condfidence interval from the above equations\n",
    "\n",
    "t_95_440 = 1.9654 # Can be retrieved from the t-table online\n",
    "\n",
    "conf_coeff_low = 304.183074 - (t_95_440 * 75.80599)\n",
    "conf_coeff_high = 304.183074 + (t_95_440 * 75.80599)\n",
    "conf_intercept_low = 152.133484 - (t_95_440 * 3.60572)\n",
    "conf_intercept_high = 152.133484 + (t_95_440 * 3.60572)\n",
    "\n",
    "print(f\"0.025 confidence level for coeff is {conf_coeff_low}\")\n",
    "print(f\"0.975 confidence level for coeff is {conf_coeff_high}\")\n",
    "print(f\"0.025 confidence level for intercept is {conf_intercept_low}\")\n",
    "print(f\"0.975 confidence level for intercept is {conf_intercept_high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic of coeff from the model is 4.012651743018033\n",
      "t-statistic of intercept from the model is 42.192219335877745\n",
      "Calculated t-statistic of coeff is 4.012651743018033\n",
      "Calculated t-statistic of intercept is 42.19221933587771\n",
      "\n",
      "HOORAY! Values are same.\n"
     ]
    }
   ],
   "source": [
    "# T-statistics from the model\n",
    "print(f\"t-statistic of coeff from the model is {results.tvalues[0]}\")\n",
    "print(f\"t-statistic of intercept from the model is {results.tvalues[1]}\")\n",
    "\n",
    "t_coeff = coeff / se_coeff\n",
    "t_intercept = intercept / se_intercept\n",
    "\n",
    "print(f\"Calculated t-statistic of coeff is {t_coeff}\")\n",
    "print(f\"Calculated t-statistic of intercept is {t_intercept}\")\n",
    "\n",
    "print()\n",
    "print(\"HOORAY! Values are same.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy\n",
    "\n",
    "RSE and RSS defined above provide the measure of fit of the model. Higher the values, worse the model fit. However the absolute value of RSE and RSS might not be very intuitive if the scale of Y is not looked at along with it.\n",
    "\n",
    "$$\n",
    "RSE = \\sqrt{\\frac{RSS}{(n-p-1)}} \\;\\; p = Number \\; of \\; features\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "To address it, we use $R^2$, which indicates the amount of variance in the data that is explained by the model. It is given by:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{TSS - RSS}{TSS} \\\\\n",
    "\\underline{R^2 = 1 - \\frac{RSS}{TSS}} \\;\\;\\;\\; where \\; TSS = \\sum(y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "TSS simply indicates the amount of variance in target variable already present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS of the model is 2528481.7816048963\n",
      "TSS of the model is 2621009.124434389\n",
      "\n",
      "R-sqaure of the model is 0.03530218264671636\n",
      "F-score of the model is 16.101374010745623\n"
     ]
    }
   ],
   "source": [
    "print(f\"RSS of the model is {results.ssr}\")\n",
    "print(f\"TSS of the model is {results.centered_tss}\")\n",
    "print()\n",
    "print(f\"R-sqaure of the model is {results.rsquared}\")\n",
    "print(f\"F-score of the model is {results.fvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify!\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{RSS}{TSS} \\;\\; = 1 - \\frac{2528481.78}{2621009.12} \\;\\; = 0.36 \\\\\n",
    "$$\n",
    "\n",
    "It seems like R-sqaure values are correct according to our formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression Equation and Residual Sum of Squares(RSS) for *p* number of predictors/features and *n* number of data points is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1  + \\hat{\\beta_2}x_2 + ... + \\hat{\\beta_p}x_p \\\\\n",
    "RSS = (y_1 - \\hat{\\beta_0} - \\hat{\\beta_1}x_{1,1} - ... - \\hat{\\beta_p}x_{1,p})^2 + (y_2 - \\hat{\\beta_0} - \\hat{\\beta_1}x_{2,1} - ... - \\hat{\\beta_p}x_{2,p})^2 + ... + (y_n - \\hat{\\beta_0} - \\hat{\\beta_1}x_{n,1} - ... - \\hat{\\beta_p}x_{n,p})^2 \\\\\n",
    "RSS = \\sum_{i=0}^n(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_{i,1} - ... - \\hat{\\beta_1}x_{i,p})^2 \\\\\n",
    "$$\n",
    "\n",
    "Since in multiple linear regression, X is a two dimensional matrix of size (n * (p + 1)) and $\\beta$ is a matrix of size ((p + 1) * 1) and Y is a matrix of size n, we will use the matrix notation to write the above equations for MLR\n",
    "\n",
    "$$\n",
    "Y = X\\beta + \\epsilon \\\\\n",
    "\\hat{Y} = X\\hat{\\beta} \\\\\n",
    "RSS = (Y - X\\hat{\\beta})^T(Y - X\\hat{\\beta})\n",
    "$$\n",
    "\n",
    "Note that in the above above matrix X and $\\beta$ have dimensions of (p+1) instead of p to accomodate for the intercept. Also RSS is of dimension 1 * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing $\\hat{\\beta}$\n",
    "\n",
    "$$\n",
    "\\frac{\\delta{RSS}}{\\delta{\\hat{\\beta}}} = -2X^T(Y - X\\hat{\\beta}) = 0 \\\\\n",
    "-X^TY + X^TX\\hat{\\beta} = 0 \\\\\n",
    "X^TX\\hat{\\beta} = X^TY \\\\\n",
    "\\underline{\\hat{\\beta} = (X^TX)^{-1}X^TY}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error of $\\hat{\\beta}$\n",
    "\n",
    "Similar to Linear regression before, we find the the standard error for $\\hat{\\beta}$ which is given by:\n",
    "\n",
    "$$\n",
    "SE(\\hat{\\beta})^2 = \\sigma^2(X^TX)^{-1} \\\\\n",
    "\\underline{SE(\\hat{\\beta_{j}})^2 = \\sigma^2(X^TX)^{-1}_{j,j}} \\\\\n",
    "$$\n",
    "\n",
    "And similarly the approximation of $\\sigma$ derived from maximum likelihood for a uncorrelated, zero mean, normally distributed $\\epsilon$, is given by Residual Standard Error\n",
    "$$\n",
    "\\sigma = RSE = \\sqrt{\\frac{RSS}{(n-p-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy\n",
    "\n",
    "We already know $R^2$ that we can use for testing the model accuracy. Along with that, to accomodate for the number of predictors, we use Adjusted $R^2$. This takes into number of predictors used in the model. This is to help filter out the predictors that might not have significant impact on the model. Their addition might reduce the R-sqaure value a bit but not enough to distinguish it from noise predictors. Its formula is given by:\n",
    "\n",
    "$$\n",
    "Adj. R^2 = 1 - \\frac{RSS/(n-p-1)}{TSS/(n-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model\n",
    "\n",
    "Similar to how we test the coefficients to see if they reject the null hypothesis and have any relationship with the target, we use the $f-statistic$ to see if the predictors and response have any relationship. Using this, we can discard the null hypothesis which says there is no relationship between the predictors and response. If that is the case then the $f-statistic$ value would be close to 1 and the p-value of $f-statistic$ would be greater than 0.05 and hence not signifcant to reject the null hypotheses. $f-statistic$ is calculated as following:\n",
    "\n",
    "$$\n",
    "F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test this out using our Diabetes dataset and using all the 10 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS of the model is 1263983.156255485\n",
      "TSS of the model is 2621009.124434389\n"
     ]
    }
   ],
   "source": [
    "X_OLS = sm.add_constant(X, prepend=False)\n",
    "model = sm.OLS(y, X_OLS)\n",
    "results = model.fit()\n",
    "print(f\"RSS of the model is {results.ssr}\")\n",
    "print(f\"TSS of the model is {results.centered_tss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                disease   R-squared:                       0.518\n",
      "Model:                            OLS   Adj. R-squared:                  0.507\n",
      "Method:                 Least Squares   F-statistic:                     46.27\n",
      "Date:                Fri, 03 Jul 2020   Prob (F-statistic):           3.83e-62\n",
      "Time:                        21:04:51   Log-Likelihood:                -2386.0\n",
      "No. Observations:                 442   AIC:                             4794.\n",
      "Df Residuals:                     431   BIC:                             4839.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age          -10.0122     59.749     -0.168      0.867    -127.448     107.424\n",
      "sex         -239.8191     61.222     -3.917      0.000    -360.151    -119.488\n",
      "bmi          519.8398     66.534      7.813      0.000     389.069     650.610\n",
      "bp           324.3904     65.422      4.958      0.000     195.805     452.976\n",
      "s1          -792.1842    416.684     -1.901      0.058   -1611.169      26.801\n",
      "s2           476.7458    339.035      1.406      0.160    -189.621    1143.113\n",
      "s3           101.0446    212.533      0.475      0.635    -316.685     518.774\n",
      "s4           177.0642    161.476      1.097      0.273    -140.313     494.442\n",
      "s5           751.2793    171.902      4.370      0.000     413.409    1089.150\n",
      "s6            67.6254     65.984      1.025      0.306     -62.065     197.316\n",
      "const        152.1335      2.576     59.061      0.000     147.071     157.196\n",
      "==============================================================================\n",
      "Omnibus:                        1.506   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404\n",
      "Skew:                           0.017   Prob(JB):                        0.496\n",
      "Kurtosis:                       2.726   Cond. No.                         227.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_OLS_T = X_OLS.transpose()\n",
    "XX_T = np.dot(X_OLS_T.to_numpy(), X_OLS.to_numpy())\n",
    "XX_T_inv = np.linalg.inv(XX_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate beta(coefficients)\n",
    "XX_T_inv_X_T = np.dot(XX_T_inv, X_OLS_T)\n",
    "beta = np.dot(XX_T_inv_X_T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_sq = results.ssr/(442-10-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated std error for age, coefficient is -10.0122, standard error of coefficient is 59.75\n",
      "Calculated std error for sex, coefficient is -239.8191, standard error of coefficient is 61.22\n",
      "Calculated std error for bmi, coefficient is 519.8398, standard error of coefficient is 66.53\n",
      "Calculated std error for bp, coefficient is 324.3904, standard error of coefficient is 65.42\n",
      "Calculated std error for s1, coefficient is -792.1842, standard error of coefficient is 416.68\n",
      "Calculated std error for s2, coefficient is 476.7458, standard error of coefficient is 339.03\n",
      "Calculated std error for s3, coefficient is 101.0446, standard error of coefficient is 212.53\n",
      "Calculated std error for s4, coefficient is 177.0642, standard error of coefficient is 161.48\n",
      "Calculated std error for s5, coefficient is 751.2793, standard error of coefficient is 171.90\n",
      "Calculated std error for s6, coefficient is 67.6254, standard error of coefficient is 65.98\n",
      "Calculated std error for const, coefficient is 152.1335, standard error of coefficient is 2.58\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for i in range(0, 11):\n",
    "    print(f\"Calculated std error for {X_OLS.columns[i]}, \"\n",
    "          f\"coefficient is {beta[i][0]:.4f}, \"\n",
    "          f\"standard error of coefficient is {math.sqrt(sigma_sq*XX_T_inv[i][i]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify other metrics as well!\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{RSS}{TSS} \\;\\; = 1 - \\frac{1263983.15}{2621009.12} \\;\\; = 0.52 \\\\\n",
    "Adj. R^2 = 1 - \\frac{RSS/(n-p-1)}{TSS/(n-1)} \\;\\; = 1 - \\frac{1263983.15/(442-10-1)}{2621009.12/(432-1)} \\;\\;\n",
    "= 1 - \\frac{3002.33}{6081.22} \\;\\; = 1 - 0.493\\;\\;  = 0.507\n",
    "$$\n",
    "\n",
    "It seems like R-sqaure and Adjusted R-sqaure values are correct according to our formula. Lets see F-statistic now\n",
    "\n",
    "$$\n",
    "F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)} \\;\\; = \\frac{(2621009.12 - 1263983.15)/10}{1263983.15/(442-10-1)} \\;\\;\n",
    "= \\frac{135702.59}{2932.67} \\;\\; = 46.27\n",
    "$$\n",
    "\n",
    "WOHOOO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed our calculated coefficients and Standard Error for all the coefficients using the formula match exactly! Using that, we can easily verify t-values as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood for Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Maximum Likelihood we can derive the same results that we did in the beginning of the notebook. This is due to the assumptions we have made about random error $\\epsilon$\n",
    "- $\\epsilon \\sim N(0, \\sigma^2)$ and is indepdent across observations and of X\n",
    "- $\\epsilon$ has constant variation\n",
    "\n",
    "Based on the above, the conditional probability density function of y is:\n",
    "$$\n",
    "\\Pi_{i=1}^np(y_i|x_i;\\beta_0, \\beta_1, \\sigma^2) \n",
    "= \\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(y_i-(\\beta_0+\\beta_1x_i))^2}{2\\sigma^2}}\n",
    "$$\n",
    "The above is called **Likelihood**\n",
    "\n",
    "Taking the Log of the above:\n",
    "$$\n",
    "log\\Pi_{i=1}^np(y_i|x_i;\\beta_0, \\beta_1, \\sigma^2) = \\sum_{i=1}^nlogp(y_i|x_i;\\beta_0, \\beta_1, \\sigma^2) \\\\\n",
    "-\\frac{n}{2}log2\\pi - nlogs - \\frac{1}{2s^2}\\sum_{i=1}^n(y_i - (\\beta_0 + \\beta_1x_i))^2\n",
    "$$\n",
    "The above is called **Log Likelihood**\n",
    "\n",
    "Now we use the derivative of the above to find $\\hat{\\beta_0}$, $\\hat{\\beta_1}$, $\\hat{\\sigma}^2$ that maximizes the log likelihood and consequently the likelihood\n",
    "\n",
    "$$\n",
    "\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x} \\\\\n",
    "\\hat{\\beta_1} = \\frac{\\sum{(y_i-\\bar{y})(x_i-\\bar{x}})}{\\sum{(x_i-\\bar{x})^2}} \\\\\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n(y_i - ({\\hat{\\beta_0}} + \\hat{\\beta_1}x_i))^2\n",
    "$$\n",
    "\n",
    "As can be seen from above, the results are same as the ones we got at the beginning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
